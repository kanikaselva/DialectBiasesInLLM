# Dialect Biases in LLM Decision Making
With Large Language Models being increasingly used to aid in decision-making, concerns about dialect and racial bias remain pressing. This study extends Hofmann et al.’s work into the healthcare domain by examining whether tweets written in African American English and Standard American English are differentially flagged for health insurance verification. Meta’s LLaMA 3 8B Instruct and Allen Institute for AI’s Olmo 3.1 32B Instruct were evaluated using a mixed-methods approach. Differences emerged across both quantitative and qualitative analyses, with variation in flag rates and justification patterns. These trends persisted even when explicit racial cues were introduced.
